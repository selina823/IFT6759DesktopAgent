{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from pathlib import Path\n",
    "\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where the DB is stored locally:\n",
    "\n",
    "When Embedded Weaviate starts for the first time, it creates a permanent datastore in the location set in your persistence_data_path. When your client exits, the Embedded Weaviate instance also exits, but the data persists . The next time the client runs, it starts a new instance of Embedded Weaviate. New Embedded Weaviate instances use the data that is saved in the datastore.\n",
    "\n",
    "## Data storage directory\n",
    "\n",
    "If XDG_DATA_HOME is set, the default is: XDG_DATA_HOME/weaviate/\n",
    "\n",
    "If XDG_DATA_HOME is not set, the default is: ~/.local/share/weaviate\n",
    "\n",
    "In my case the data is stored in the following location: /Users/username/.local/share/weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(\n",
    "        additional_env_vars={\"X-HuggingFace-Api-Key\": \"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\"}\n",
    "    )\n",
    ")\n",
    "assert client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the structure of the data vector dabase: We called it PDF_Document. This is the \"Class\" that we are going to use to store the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.delete_all()\n",
    "# Create a new class with a vectorizer\n",
    "schema = {\n",
    "    \"class\": \"PDF_Document\",    \n",
    "    \"vectorizer\": \"text2vec-huggingface\",\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"content\",  #What we want to vectorize\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Content of PDF\",\n",
    "            \"moduleConfig\": {\n",
    "                \"text2vec-huggingface\": {\"skip\": False, \"vectorizePropertyName\": False}\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"filename\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"PDF filename\"\n",
    "        },\n",
    "    ],\n",
    "    \"moduleConfig\": {\n",
    "    \"text2vec-huggingface\": {\n",
    "      \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",  # Can be any public or private Hugging Face model.\n",
    "      \"options\": {\n",
    "        \"waitForModel\": True,  # Try this if you get a \"model not ready\" error\n",
    "      }\n",
    "}\n",
    "}\n",
    "}\n",
    "\n",
    "client.schema.create_class(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.documents.elements import DataSourceMetadata\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from weaviate.util import generate_uuid5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(elements, chunk_under_n_chars=500, chunk_new_after_n_chars=1500):\n",
    "\n",
    "    chunks = chunk_by_title(\n",
    "        elements,\n",
    "        multipage_sections=False, # If True, the title of the first page is used for all pages\n",
    "        combine_text_under_n_chars=chunk_under_n_chars,\n",
    "        new_after_n_chars=chunk_new_after_n_chars\n",
    " \n",
    "    )\n",
    "\n",
    "    for i in range(len(chunks)):\n",
    "        chunks[i] = {\"text\": chunks[i].text, \"filename\": chunks[i].metadata.filename}\n",
    "\n",
    "    chunk_texts = [x['text'] for x in chunks]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# def add_data_to_weaviate(files, client, chunk_under_n_chars=500, chunk_new_after_n_chars=1500):\n",
    "#     for filename in files:\n",
    "#         try:\n",
    "#             elements = partition_pdf(filename=filename)\n",
    "#             chunks = get_chunks(elements, chunk_under_n_chars, chunk_new_after_n_chars)\n",
    "#         except IndexError as e:\n",
    "#             print(e)\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Uploading {len(chunks)} chunks for {str(filename)}.\")\n",
    "#         for i, chunk in enumerate(chunks):\n",
    "#             try:\n",
    "#                 client.data_object.create(class_name=\"PDF_Document\", data_object={\"content\": chunk['text'], \"filename\": filename})\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#                 print(f\"Failed to upload chunk {i} for {str(filename)}.\")\n",
    "\n",
    "#         with client.batch as batch:\n",
    "#             for data_object in chunks:\n",
    "#                 batch.add_data_object(data_object={\"content\": chunk['text'], \"filename\": filename}, class_name=\"PDF_Document\", uuid=generate_uuid5(data_object))\n",
    "\n",
    "        \n",
    "#     client.batch.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate import Client\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "def configure_batch(client: Client, batch_size: int, batch_target_rate: int):\n",
    "    \"\"\"\n",
    "    Configure the weaviate client's batch so it creates objects at `batch_target_rate`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client : Client\n",
    "        The Weaviate client instance.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    batch_target_rate : int\n",
    "        The batch target rate as # of objects per second.\n",
    "    \"\"\"\n",
    "\n",
    "    def callback(batch_results: dict) -> None:\n",
    "\n",
    "        # you could print batch errors here\n",
    "        time_took_to_create_batch = batch_size * (client.batch.creation_time/client.batch.recommended_num_objects)\n",
    "        time.sleep(\n",
    "            max(batch_size/batch_target_rate - time_took_to_create_batch + 1, 15)\n",
    "        )\n",
    "\n",
    "    client.batch.configure(\n",
    "        batch_size=batch_size,\n",
    "        timeout_retries=5,\n",
    "        callback=callback,\n",
    "    )\n",
    "\n",
    "# def add_data_to_weaviate(files, client, chunk_under_n_chars=500, chunk_new_after_n_chars=1500, batch_size=10, batch_target_rate=2):\n",
    "#     configure_batch(client, batch_size, batch_target_rate)\n",
    "\n",
    "#     for i, filename in enumerate(files):\n",
    "#         print(f\"Processing file {i+1}/{len(files)}: {filename}\")  # print the current file being processed\n",
    "#         try:\n",
    "#             elements = partition_pdf(filename=filename)\n",
    "#             chunks = get_chunks(elements, chunk_under_n_chars, chunk_new_after_n_chars)\n",
    "#         except IndexError as e:\n",
    "#             print(e)\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Uploading {len(chunks)} chunks for {str(filename)}.\")\n",
    "#         with client.batch as batch:\n",
    "#             for i, chunk in enumerate(chunks):\n",
    "#                 data_object = {\"content\": chunk['text'], \"filename\": filename}\n",
    "#                 try:\n",
    "#                     batch.add_data_object(data_object=data_object, class_name=\"PDF_Document\", uuid=uuid.uuid5(uuid.NAMESPACE_DNS, str(data_object)))\n",
    "#                 except Exception as e:\n",
    "#                     print(e)\n",
    "#                     print(f\"Failed to add chunk {i} to batch for {str(filename)}. Continuing with next chunk.\")\n",
    "#                     continue  # continue with the next chunk if an error occurred\n",
    "\n",
    "#         print(f\"Flushing batch for {str(filename)}.\")\n",
    "#         client.batch.flush()\n",
    "\n",
    "# Ensure the uuid module is imported\n",
    "\n",
    "def add_data_to_weaviate(files, client, chunk_under_n_chars=500, chunk_new_after_n_chars=1500, batch_size=5, batch_target_rate=2):\n",
    "    configure_batch(client, batch_size, batch_target_rate)  # Assuming this correctly configures the batch\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            elements = partition_pdf(filename=filename)  # Load and process data from files\n",
    "            chunks = get_chunks(elements, chunk_under_n_chars, chunk_new_after_n_chars)  # Create manageable chunks\n",
    "\n",
    "            print(f\"Uploading {len(chunks)} chunks for {str(filename)}.\")\n",
    "\n",
    "            with client.batch(batch_size=10 ) as batch:\n",
    "                for chunk in chunks:\n",
    "                    # Print the current chunk being processed  \n",
    "                    data_object = {\n",
    "                        \"content\": chunk['text'],\n",
    "                        \"filename\": filename\n",
    "                    }\n",
    "        \n",
    "                    try:\n",
    "\n",
    "                        batch.add_data_object(\n",
    "                            data_object=data_object,\n",
    "                            class_name=\"PDF_Document\",\n",
    "                            uuid=generate_uuid5(data_object)\n",
    "                        )\n",
    "                \n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to add data object to batch for {filename}: {e}\")\n",
    "                        continue\n",
    "     \n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the files to the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path = '../data/coursematerial/'\n",
    "import glob\n",
    "# Dictionary to hold file names and their elements\n",
    "\n",
    "# Find all PDF files in the specified directory\n",
    "pdf_files = glob.glob(os.path.join(directory_path, '*.pdf'))\n",
    "\n",
    "add_data_to_weaviate(\n",
    "    files=pdf_files,\n",
    "    client=client,\n",
    "    chunk_under_n_chars=250,\n",
    "    chunk_new_after_n_chars=500,\n",
    "    batch_size=5,\n",
    "    batch_target_rate=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query.aggregate(\"PDF_Document\").with_meta_count().do()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells below are two examples of queries to the database to get the data you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "client = weaviate.Client(\"http://localhost:8079\") # Replace with your endpoint\n",
    "some_objects = client.data_object.get()\n",
    "print(json.dumps(some_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(\"http://localhost:8079\")\n",
    "# Perform a query\n",
    "query1 = \"\"\"\n",
    "{\n",
    "  Get {\n",
    "    PDF_Document (limit: 20) {\n",
    "      content\n",
    "      filename\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "result = client.query.raw(query1)\n",
    "print(result)\n",
    "\n",
    "\n",
    "# print which files are in the results\n",
    "for file in result['data']['Get']['PDF_Document']:\n",
    "    print(file['filename'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "{\n",
    "  Get {\n",
    "    PDF_Document (limit: 2000) {\n",
    "      content\n",
    "      filename\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = client.query.raw(query1)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "{\n",
    "  Aggregate {\n",
    "    PDF_Document {\n",
    "      meta {\n",
    "        count\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = client.query.raw(query2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift-6758",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
