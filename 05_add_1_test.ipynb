{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.4\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "weaviate_version = weaviate.__version__\n",
    "print(weaviate_version)\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from pathlib import Path\n",
    "import weaviate\n",
    "import os\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import os\n",
    "import weaviate.classes as wvc\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.documents.elements import DataSourceMetadata\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from weaviate.util import generate_uuid5\n",
    "import time\n",
    "import glob\n",
    "from uuid import uuid5, NAMESPACE_DNS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "WeaviateStartUpError",
     "evalue": "Embedded DB did not start because processes are already listening on ports http:8079 and grpc:50050use weaviate.connect_to_local(port=8079, grpc_port=50050) to connect to the existing instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWeaviateStartUpError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m weaviate\u001b[38;5;241m.\u001b[39mconnect_to_embedded(\n\u001b[1;32m      2\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# e.g. version=\"1.23.10\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-HuggingFace-Api-Key\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_SzaiWGfpZEXDaqyfYcitHfXETTnpmUiMgg\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Replace with your API key\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     },\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/connect/helpers.py:243\u001b[0m, in \u001b[0;36mconnect_to_embedded\u001b[0;34m(hostname, port, grpc_port, headers, additional_config, version, persistence_data_path, binary_path, environment_variables)\u001b[0m\n\u001b[1;32m    237\u001b[0m     options\u001b[38;5;241m.\u001b[39mbinary_path \u001b[38;5;241m=\u001b[39m binary_path\n\u001b[1;32m    238\u001b[0m client \u001b[38;5;241m=\u001b[39m WeaviateClient(\n\u001b[1;32m    239\u001b[0m     embedded_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    240\u001b[0m     additional_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    241\u001b[0m     additional_config\u001b[38;5;241m=\u001b[39madditional_config,\n\u001b[1;32m    242\u001b[0m )\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m __connect(client)\n",
      "File \u001b[0;32m~/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/connect/helpers.py:345\u001b[0m, in \u001b[0;36m__connect\u001b[0;34m(client)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    344\u001b[0m     client\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/connect/helpers.py:341\u001b[0m, in \u001b[0;36m__connect\u001b[0;34m(client)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__connect\u001b[39m(client: WeaviateClient) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m WeaviateClient:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 341\u001b[0m         client\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m client\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/client.py:282\u001b[0m, in \u001b[0;36mWeaviateClient.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_connected():\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__skip_init_checks)\n",
      "File \u001b[0;32m~/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/connect/v4.py:655\u001b[0m, in \u001b[0;36mConnectionV4.connect\u001b[0;34m(self, skip_init_checks)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, skip_init_checks: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconnect(skip_init_checks)\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# create GRPC channel. If Weaviate does not support GRPC then error now.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_params\u001b[38;5;241m.\u001b[39m_grpc_channel(\n\u001b[1;32m    658\u001b[0m         async_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, proxies\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxies\n\u001b[1;32m    659\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/connect/v4.py:135\u001b[0m, in \u001b[0;36m_Connection.connect\u001b[0;34m(self, skip_init_checks)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, skip_init_checks: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedded_db \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedded_db\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_clients(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth, skip_init_checks)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/embedded.py:294\u001b[0m, in \u001b[0;36mEmbeddedV4.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m up \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_listening()\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m up[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m up[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateStartUpError(\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedded DB did not start because processes are already listening on ports http:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and grpc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrpc_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse weaviate.connect_to_local(port=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, grpc_port=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mgrpc_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) to connect to the existing instance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m up[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m up[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateStartUpError(\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedded DB did not start because a process is already listening on port http:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlook for another free port for the HTTP connection to you embedded instance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m     )\n",
      "\u001b[0;31mWeaviateStartUpError\u001b[0m: Embedded DB did not start because processes are already listening on ports http:8079 and grpc:50050use weaviate.connect_to_local(port=8079, grpc_port=50050) to connect to the existing instance"
     ]
    }
   ],
   "source": [
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"latest\",  # e.g. version=\"1.23.10\"\n",
    "    headers={\n",
    "        \"X-HuggingFace-Api-Key\": \"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\" # Replace with your API key\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitiono PDF with unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_files(directory_path):\n",
    "    # Dictionary to hold file names and their elements\n",
    "    files_elements = {}\n",
    "\n",
    "    # Find all PDF files in the specified directory recursively\n",
    "    pdf_files = glob.glob(f\"{directory_path}/**/*.pdf\", recursive=True)\n",
    "\n",
    "    # Iterate over each PDF file found\n",
    "    for pdf_file in pdf_files:\n",
    "        # Extract elements from the PDF\n",
    "        elements = partition_pdf(pdf_file)\n",
    "\n",
    "        # Extract the folder name from the path of the PDF file\n",
    "        folder_name = os.path.basename(os.path.dirname(pdf_file))\n",
    "\n",
    "        # Convert each element to a string (assuming each element has a .text attribute or similar)\n",
    "        elements_text = [str(elem.text) if hasattr(elem, 'text') else str(elem) for elem in elements]\n",
    "\n",
    "        # Extract the file name without extension to use as a key\n",
    "        file_name = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "\n",
    "        # Create a unique key using folder name and file name\n",
    "        unique_key = (folder_name, file_name)\n",
    "\n",
    "        # Store the elements in the dictionary under the unique key\n",
    "        files_elements[unique_key] = elements_text\n",
    "\n",
    "        print(f\"Processed elements from {pdf_file} stored under key {unique_key}\")\n",
    "\n",
    "    return files_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For UT_CS411 NOT USED ANYMORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_questions_refined_UT(elements):\n",
    "    text = \"\\n\".join(str(elem) for elem in elements)\n",
    "    \n",
    "    # Patterns for main questions and subquestions\n",
    "    main_question_pattern = re.compile(r'(\\d+)\\.\\s*(.*?)\\s*(?=\\n\\d+\\.|$)', re.DOTALL)\n",
    "    subquestion_pattern = re.compile(r'\\n\\s*\\(([a-z])\\)\\s*(.*?)(?=\\n\\s*\\([a-z]\\)\\s*|\\n\\d+\\.|$)', re.DOTALL)\n",
    "    \n",
    "    questions = {}\n",
    "    \n",
    "    # Match and store main questions\n",
    "    for main_match in main_question_pattern.finditer(text):\n",
    "        main_question_number = main_match.group(1)\n",
    "        main_question_text = main_match.group(2).strip()\n",
    "        questions[main_question_number] = {\n",
    "            \"text\": main_question_text.split(\"\\n\", 1)[0],\n",
    "            \"subquestions\": []\n",
    "        }\n",
    "\n",
    "    # Match and store subquestions\n",
    "    for sq_match in subquestion_pattern.finditer(text):\n",
    "        subquestion_letter = sq_match.group(1).strip()\n",
    "        subquestion_text = sq_match.group(2).strip()\n",
    "\n",
    "        # Determine the appropriate main question for each subquestion\n",
    "        previous_main_question_number = None\n",
    "        for mq_number in questions:\n",
    "            if text.find(\"\\n\" + mq_number + \".\") < sq_match.start():\n",
    "                previous_main_question_number = mq_number\n",
    "\n",
    "        # Add the subquestion to the identified main question\n",
    "        if previous_main_question_number:\n",
    "            questions[previous_main_question_number][\"subquestions\"].append((subquestion_letter, subquestion_text))\n",
    "   \n",
    "    return questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_questions_combined_UBC_MT(elements):\n",
    "    text = \"\\n\".join(str(elem) for elem in elements)\n",
    "    \n",
    "    # Combined patterns for main questions and subquestions\n",
    "    main_question_pattern = re.compile(r'(?:\\[\\d+\\]\\s*)?(\\d+)\\.\\s*(.*?)(?=(?:\\n(?:\\[\\d+\\]\\s*)?\\d+\\.|\\Z))', re.DOTALL)\n",
    "    subquestion_pattern = re.compile(r'\\n\\s*\\(([a-z])\\)\\s*(.*?)(?=\\n\\s*\\([a-z]\\)\\s*|(?:\\n(?:\\[\\d+\\]\\s*)?\\d+\\.|\\Z))', re.DOTALL)\n",
    "    \n",
    "    questions = {}\n",
    "    \n",
    "    # Match and store main questions\n",
    "    for main_match in main_question_pattern.finditer(text):\n",
    "        main_question_number = main_match.group(1)\n",
    "        main_question_text = main_match.group(2).strip()\n",
    "        questions[main_question_number] = {\n",
    "            \"text\": main_question_text.split(\"\\n\", 1)[0],\n",
    "            \"subquestions\": [],\n",
    "            \"end_position\": main_match.end()  # Store the end position of the main question\n",
    "        }\n",
    "\n",
    "    # Match and store subquestions\n",
    "    for sq_match in subquestion_pattern.finditer(text):\n",
    "        subquestion_letter = sq_match.group(1).strip()\n",
    "        subquestion_text = sq_match.group(2).strip()\n",
    "\n",
    "        # Determine the appropriate main question for each subquestion\n",
    "        # by finding the main question whose end position is right before the subquestion\n",
    "        previous_main_question_number = None\n",
    "        previous_main_question_end_position = -1\n",
    "        for mq_number, mq_details in questions.items():\n",
    "            if mq_details[\"end_position\"] < sq_match.start() and mq_details[\"end_position\"] > previous_main_question_end_position:\n",
    "                previous_main_question_number = mq_number\n",
    "                previous_main_question_end_position = mq_details[\"end_position\"]\n",
    "\n",
    "        # Add the subquestion to the identified main question\n",
    "        if previous_main_question_number is not None:\n",
    "            questions[previous_main_question_number][\"subquestions\"].append((subquestion_letter, subquestion_text))\n",
    "   \n",
    "    return questions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global pattern matching for ALL exams for ALL courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_exam_questions(text):\n",
    "    text = \"\\n\".join(str(elem) for elem in text)\n",
    "    questions = {}\n",
    "    # # Subquestion regex matches a letter in parentheses, followed by any text, and ensures it's not immediately followed by another subquestion or main question.\n",
    "    subquestion_pattern = re.compile(r'\\n\\s*\\(([a-z])\\)\\s*(.*?)(?=\\n\\s*\\([a-z]\\)\\s*|\\n\\d+\\.|\\Z)', re.DOTALL)\n",
    "    # Main question regex to match \"Question\" or a number followed by a period at the start of a line, potentially with bracketed points\n",
    "    main_question_pattern = re.compile(r'^(?:\\[\\d+\\]\\s*)?(?:Question\\s+|Problem\\s+)?(\\d+)\\.\\s*(.*?)(?=\\n(?:\\[\\d+\\]\\s*)?(?:Question\\s+|Problem\\s+)?\\d+\\.|\\Z)', re.MULTILINE | re.DOTALL)\n",
    "\n",
    "    alternative_subquestion_pattern = re.compile(r'\\n\\s*([a-z])\\)\\s*(.*?)\\s*(?=\\n\\s*[a-z]\\)\\s*|\\n\\d+\\.|\\Z)', re.DOTALL)\n",
    "    \n",
    "    # Match and store main questions\n",
    "    for main_match in main_question_pattern.finditer(text):\n",
    "        #print(main_match , \"-----------------------------------------------MAINMATCH\")\n",
    "        main_question_number = main_match.group(1)\n",
    "        main_question_text = main_match.group(2).strip()\n",
    "        \n",
    "\n",
    "        # check if the main question number is already in the dictionary\n",
    "        if main_question_number in questions:\n",
    "            # If the text is empty, replace it with the new text\n",
    "            if not questions[main_question_number][\"text\"]:\n",
    "                questions[main_question_number][\"text\"] = main_question_text\n",
    "            else:\n",
    "                # Skip this main question if it already has text\n",
    "                continue\n",
    "            \n",
    "        # Initialize a new main question with potential placeholder for text\n",
    "        questions[main_question_number] = {\n",
    "            \"text\": \"\",\n",
    "            \"subquestions\": []\n",
    "        }\n",
    "\n",
    "        # If there is text for the main question, set it\n",
    "        if main_question_text:\n",
    "            questions[main_question_number][\"text\"] = main_question_text\n",
    "\n",
    "    # If no main questions are found, look for exceptions\n",
    "    if not questions:\n",
    "\n",
    "         # Match and store main questions\n",
    "        main_question_pattern = re.compile(r'Problem\\s+(\\d+):\\s*(.*?)(?=(?:\\n\\[?\\d+\\])?\\s*Problem\\s+\\d+:|\\Z)', re.DOTALL)\n",
    "        \n",
    "        for main_match in main_question_pattern.finditer(text):\n",
    "            #print(main_match , \"-----------------------------------------------MAINMATCH\")\n",
    "            question_num = main_match.group(1)\n",
    "            question_text = main_match.group(2).strip()\n",
    "            questions[question_num] = {\"text\": question_text, \"subquestions\": []}\n",
    "\n",
    "        # Match and store subquestions\n",
    "        subquestion_pattern = re.compile(r'\\[(\\d+)\\]\\s*\\(([a-z])\\)\\s*(.*?)(?=\\n\\[\\d+\\]\\s*\\([a-z]\\)|\\nProblem\\s+\\d+:|\\Z)', re.DOTALL)\n",
    "        \n",
    "        for sq_match in subquestion_pattern.finditer(text):\n",
    "            subquestion_letter = sq_match.group(2)\n",
    "            subquestion_text = sq_match.group(3).strip()\n",
    "\n",
    "            # Add the subquestion to the closest preceding main question\n",
    "            for q_num in reversed(questions.keys()):\n",
    "                if text.rfind('Problem ' + q_num + ':', 0, sq_match.start()) != -1:\n",
    "                    questions[q_num][\"subquestions\"].append((subquestion_letter, subquestion_text))\n",
    "                    break\n",
    "\n",
    "\n",
    "    # Match and store subquestions\n",
    "    for sq_match in subquestion_pattern.finditer(text):\n",
    "\n",
    "        subquestion_letter = sq_match.group(1).strip()\n",
    "        subquestion_text = sq_match.group(2).strip()\n",
    "        \n",
    "        # Find the closest preceding main question number\n",
    "        closest_main_question_number = max(filter(lambda num: text.find(\"\\n\" + num + \".\") < sq_match.start(), questions), default=None)\n",
    "        \n",
    "        if closest_main_question_number:\n",
    "            # Add subquestion text to the main question if it's empty\n",
    "            if not questions[closest_main_question_number][\"text\"]:\n",
    "                questions[closest_main_question_number][\"text\"] = subquestion_text\n",
    "            else:\n",
    "                questions[closest_main_question_number][\"subquestions\"].append((subquestion_letter, subquestion_text))\n",
    "\n",
    "    # If no subquestions with parentheses are found, try without parentheses\n",
    "    if all(len(q[\"subquestions\"]) == 0 for q in questions.values()):\n",
    "        print(\"No subquestions found with parentheses, trying without...\")  \n",
    "        for sq_match in alternative_subquestion_pattern.finditer(text):\n",
    "            print(\"alternative_subquestion_pattern\")\n",
    "            subquestion_letter = sq_match.group(1)\n",
    "            subquestion_text = sq_match.group(2).strip()\n",
    "                    # Find the closest preceding main question number\n",
    "            closest_main_question_number = max(filter(lambda num: text.find(\"\\n\" + num + \".\") < sq_match.start(), questions), default=None)\n",
    "            \n",
    "            if closest_main_question_number:\n",
    "                # Add subquestion text to the main question if it's empty\n",
    "                if not questions[closest_main_question_number][\"text\"]:\n",
    "                    questions[closest_main_question_number][\"text\"] = subquestion_text\n",
    "                else:\n",
    "                    questions[closest_main_question_number][\"subquestions\"].append((subquestion_letter, subquestion_text))\n",
    "\n",
    "\n",
    "    return questions\n",
    "\n",
    "# Use actual OCR-extracted text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process file elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Processed elements from data/test/UBC_MT307/307_2015WT1.pdf stored under key ('UBC_MT307', '307_2015WT1')\n",
      "Processed elements from data/test/UBC_MT307/307_2012WT2.pdf stored under key ('UBC_MT307', '307_2012WT2')\n",
      "Processed elements from data/test/UBC_MT307/307_2014WT1.pdf stored under key ('UBC_MT307', '307_2014WT1')\n",
      "Processed elements from data/test/UT_CS411/CSC311f19_final.pdf stored under key ('UT_CS411', 'CSC311f19_final')\n",
      "Processed elements from data/test/UT_CS411/CSC411f18_midterm2.pdf stored under key ('UT_CS411', 'CSC411f18_midterm2')\n",
      "Processed elements from data/test/UT_CS411/CSC411f18_midterm1.pdf stored under key ('UT_CS411', 'CSC411f18_midterm1')\n",
      "Processed elements from data/test/UBC_ST302/midterm201.pdf stored under key ('UBC_ST302', 'midterm201')\n",
      "Processed elements from data/test/UBC_ST302/midterm202.pdf stored under key ('UBC_ST302', 'midterm202')\n",
      "Processed elements from data/test/UBC_ST302/1999-final.pdf stored under key ('UBC_ST302', '1999-final')\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the PDF files\n",
    "directory_path = 'data/test'\n",
    "directory= os.path.split(directory_path)[-1]\n",
    "print(directory)\n",
    "#process the pdf files\n",
    "files_elements = process_pdf_files(directory_path)\n",
    "#print(files_elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not used it was for each individual course only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, elements in files_elements.items():\n",
    "    parsed_questions ={}\n",
    "\n",
    "    # Apply the parse_questions function to the elements of the current file\n",
    "    if file_name.startswith(\"307\"):\n",
    "        print(file_name)\n",
    "        parsed_questions = parse_questions_combined_UBC_MT(files_elements[file_name])\n",
    "    else:\n",
    "        print(file_name)\n",
    "        parsed_questions = parse_questions_refined_UT(files_elements[file_name])\n",
    "\n",
    "    # Iterate through the parsed questions and print them along with their subquestions\n",
    "    for question_num, question_info in parsed_questions.items():\n",
    "        #print(f\"Processing question_num: {question_num}, question_info: {question_info}\")\n",
    "        print(f\"Question {question_num}: {question_info['text']}\")\n",
    "        for subq in question_info[\"subquestions\"]:\n",
    "            print(f\" ----sub {subq[0]}: {subq[1]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307_2015WT1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Apply the parse_questions function to the elements of the current file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_name)\n\u001b[0;32m----> 6\u001b[0m parsed_questions \u001b[38;5;241m=\u001b[39m parse_exam_questions(files_elements[file_name])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parsed_questions:  \u001b[38;5;66;03m# Add a test to see if the content is empty\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------------------------------No content found for exam \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "for file_name, elements in files_elements.items():\n",
    "    parsed_questions ={}\n",
    "\n",
    "    # Apply the parse_questions function to the elements of the current file\n",
    "    print(file_name)\n",
    "    parsed_questions = parse_exam_questions(files_elements[file_name])\n",
    "    if not parsed_questions:  # Add a test to see if the content is empty\n",
    "        print(f\"------------------------------------------------No content found for exam {file_name}.\\n\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Iterate through the parsed questions and print them along with their subquestions\n",
    "    for question_num, question_info in parsed_questions.items():\n",
    "        #print(f\"Processing question_num: {question_num}, question_info: {question_info}\")\n",
    "        print(f\"QUESTION------------------ {question_num}: {question_info['text']}\")\n",
    "        for subq in question_info[\"subquestions\"]:\n",
    "            print(f\" -------sub {subq[0]}: {subq[1]}\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard exam_content_PhTvGR1DAP4M in 4.378136ms\",\"time\":\"2024-04-29T12:11:25-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-04-29T12:11:25-04:00\",\"took\":126685}\n"
     ]
    }
   ],
   "source": [
    "client.collections.delete(name=\"exam_content\")\n",
    "\n",
    "\n",
    "questions = client.collections.create(\n",
    "\"exam_content\",\n",
    "vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_huggingface(\n",
    "        model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        vectorize_collection_name=True\n",
    "),\n",
    "properties=[  \n",
    "    wvc.config.Property(name=\"mainQuestion\", data_type=wvc.config.DataType.TEXT),\n",
    "    wvc.config.Property(name=\"QuestionNumber\", data_type=wvc.config.DataType.TEXT),\n",
    "    wvc.config.Property(name=\"subQuestion\", data_type=wvc.config.DataType.TEXT),\n",
    "    wvc.config.Property(name=\"filename\", data_type=wvc.config.DataType.TEXT),\n",
    "    # Add a 'course' property to store the course directory name\n",
    "    wvc.config.Property(name=\"course\", data_type=wvc.config.DataType.TEXT),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the objects that will be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC_MT307\n",
      "307_2015WT1\n",
      "UBC_MT307\n",
      "307_2012WT2\n",
      "UBC_MT307\n",
      "307_2014WT1\n",
      "UT_CS411\n",
      "CSC311f19_final\n",
      "No subquestions found with parentheses, trying without...\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "alternative_subquestion_pattern\n",
      "UT_CS411\n",
      "CSC411f18_midterm2\n",
      "UT_CS411\n",
      "CSC411f18_midterm1\n",
      "UBC_ST302\n",
      "midterm201\n",
      "UBC_ST302\n",
      "midterm202\n",
      "No subquestions found with parentheses, trying without...\n",
      "UBC_ST302\n",
      "1999-final\n"
     ]
    }
   ],
   "source": [
    "question_objs = list()\n",
    "count = 0\n",
    "for file_course, elements in files_elements.items():\n",
    "\n",
    "    parsed_questions ={}\n",
    "\n",
    "    # # Apply the parse_questions function to the elements of the current file\n",
    "    # if file_course[1].startswith(\"307\"):\n",
    "    #      print(file_course)\n",
    "    #      parsed_questions = parse_questions_combined_UBC_MT(files_elements[file_course])\n",
    "    # # else:\n",
    "    #     print(file_name)\n",
    "    #     parsed_questions = parse_questions_refined_UT(files_elements[file_name])\n",
    "   \n",
    "\n",
    "    #print(file_course[0])\n",
    "    #print(file_course[1])\n",
    "    parsed_questions= parse_exam_questions(files_elements[file_course])\n",
    "\n",
    "    \n",
    "    for question, details in parsed_questions.items():  # Batch import data\n",
    "        #print(f\"-----------------FILENAME: {file_course[1]}\") # Print the filename\n",
    "        #print(f\"---------importing question: {question}, details: {details}\")\n",
    "        if len(details[\"subquestions\"]) == 0:  # if there are no subquestions\n",
    "            properties = {\n",
    "                \"mainQuestion\": details[\"text\"],\n",
    "                \"QuestionNumber\": question,\n",
    "                \"subQuestion\": \"\",\n",
    "                \"filename\": file_course[1],\n",
    "                \"course\": file_course[0]\n",
    "            }\n",
    "            question_objs.append(properties)\n",
    "        else: \n",
    "            for subq in details[\"subquestions\"]:\n",
    "                #print(f\"-----importing subquestion: {subq[1]}\")\n",
    "            \n",
    "                properties = {\n",
    "                    \"mainQuestion\": details[\"text\"],\n",
    "                    \"QuestionNumber\": question,\n",
    "                    \"subQuestion\": subq[1],\n",
    "                    \"filename\": file_course[1],\n",
    "                    \"course\": file_course[0]\n",
    "                }\n",
    "                question_objs.append(properties)\n",
    "        count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 60 questions\n"
     ]
    }
   ],
   "source": [
    "print(f\"Importing {count} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 60\n"
     ]
    }
   ],
   "source": [
    "# ===== Batch import =====\n",
    "with questions.batch.dynamic() as batch:\n",
    "    for data_row in question_objs:\n",
    "        obj_uuid = uuid5(NAMESPACE_DNS, data_row[\"mainQuestion\"]+ data_row[\"filename\"])\n",
    "        batch.add_object(\n",
    "            properties=data_row,\n",
    "            uuid=obj_uuid\n",
    "        )\n",
    "        \n",
    "print(\"Total chunks:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks in Wv: 0\n"
     ]
    }
   ],
   "source": [
    "lecture_content = client.collections.get(\"exam_content\")\n",
    "response_ttl = lecture_content.aggregate.over_all(total_count=True)\n",
    "\n",
    "print( \"Total Chunks in Wv:\",response_ttl.total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift-6758",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
